---
title: "02-01-datamgt"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Creating and importing data

Let's look at a couple of ways of creating a small dataset. First, we will generate a matrix and cast it into a tibble. Then we will create a dataset of variables of different type.

## Creating a toy dataset

First, load the required libraries

```{r echo=FALSE}
library(tidyverse)

```

```{r}

mydata1 <- tibble(one = 1:10, two = 11:20, three = 21:30)

str(mydata1)
mydata2 <- as_tibble(matrix(1:30, ncol = 3))
names(mydata2) <- c("one", "two", "three")

nstr <- names(mydata2)
nstr
str(mydata1)
str(mydata2)

# The traditional way is:
mydata1b <- data.frame(one = 1:10, two = 11:20, three = 21:30)
# or, converting a matrix into a data frame
mydata2b <- as.data.frame(matrix(1:30, ncol = 3))
names(mydata2b) <- c("one", "two", "three")

str(mydata1b)
str(mydata2b)

rm(mydata2, mydata1b, mydata2b)
```

```{r}

```

## importing data from excel and csv

There are two packages that we will use to import data. `readr` package is used to import csv files and `readxl` is used to read excel files. Though the preference is to use the .csv format. Also, note that the data file is stored in a separate folder, /data within the project folder. This is good practice as it separates out code from data. Some large project may involve setting up two folders: /data_raw and /data_clean.

```{r}
library(readr)
library(readxl)
library(skimr)
library(mlbadata)

#Pressing tab in quotes will pull up the list of files
roxbury_tb <- read_csv("data/WestRoxbury.csv")
roxbury_df <- read.csv("data/WestRoxbury.csv")

skim(roxbury_df)
roxbury_tb
skim(roxbury_tb)
glimpse(roxbury_tb)
glimpse(roxbury_df)

#Create a new variable

roxbury_tb$extra_area <- roxbury_tb$`GROSS AREA` - roxbury_tb$`LIVING AREA`
extra_area2 <- roxbury_tb$`GROSS AREA` - roxbury_tb$`LIVING AREA`
# We can export into a csv
write_csv(roxbury_tb, "data/new_roxbury.csv")

#Another option is to save in .rds, which is native r format.
write_rds(roxbury_tb, "data/roxbury.rds")

#We can read this in R
#roxbury.new <-  read_rds("data/roxbury.rds")

# Finally, excel can be read in as follows:

housing.data <- read_excel("data/BostonHousing.xlsx")

```

**Note:** The above method of reading csvs `read_csv()`, works well when you have external data files, ideally, in the same project. Then, put `""` marks in the parenthesis and press `tab`. R will open up the existing file and folders in the current project directory and you can choose the appropriate data file.

However, in general, all the datasets used in this course are contained in the `mlbdadata` library which I have already loaded in the environment. Datasets within this library (or any other `R` library, can be easily loaded using the following command:

```{r}
roxbury.df <- mlbadata::WestRoxbury
# to preview this data:
glimpse(roxbury.df)
skim(roxbury.df)

```

There are some important points to note in the `roxbury_tb` dataframe. Some variable names have spaces. The default command, `read.csv()` would have inserted `.` between the words, `TOTAL.VALUE`.

**Accessing a given variable from the data and doing some basic operations:**

There are two common ways to access a variable, one with the \$ accessor and one with a column reference. *Each will result in a different class of results and that has implications on what can be done with them*. To get the column names of a dataset, we can use `names()` function:

```{r}
names(mydata1)[2:3]
```

Let's pull out col 2.

```{r}
# Get column 2, with the $ accessor
mydata1$two[1:5]
mydata1[1:5 , 2]
mydata1[[2]]
str(mydata1$two)
class(mydata1$two)
```

The result is a vector object, which is most flexible and permits direct mathematical operations. For example,

```{r}
mean(mydata1$two)
mean(mydata1[,2])

summary(mydata1[,2])
```

The second way is to use a column reference. This creates a new dataset which is a subset of the old dataset.

```{r}
mydata1[ , "two"] #the above returns a tibble
mydata1[c(3,4,8) , c("one", "three")]
#Let's examine it.
class(mydata1[, "two"])
str(mydata1[, "two"])

# We could also refer to is by it's location

mydata1[ , 2]

# If we just want to extract that one column as a vector,

mydata1[[2]] # Note: This is same as mydata$two

# mydata1[ , 2] is a more flexible way of extracting data and we will generally use this. Let's say we wanted first 5 rows and cols 1 and 3

mydata1[1:5, c(1,3)]
class(mydata1[1:5, c(1,3)])

```

The structure of these objects still is dataframe (tibble). Standard math functions, like `mean()` do not work on datafames but on vectors. Try,

`mean(d2)`

The above function will work over a vector and even a martix and will give us the mean of the entire matrix.

```{r}
mymat <- matrix(1:30, nrow = 10)
mymat
mean(mymat)
max(mymat)
median(mymat)
```

We will learn later on how to apply functions iteratively to elements of a list using a paradigm called `functional programming`.

### Treatment of factor variables

`REMODEL` has three values, "recent, none and old". We want to make this into a factor variable and also make recent as the first level, followed by old and then none. The function `factor()` will make a column into a factor with the levels being sorted in alphabetical order. But here, we will specify our own levels.

```{r}
roxbury_tb$REMODEL <- factor(roxbury_tb$REMODEL,
                         levels = c("Recent", "Old", "None"))
glimpse(roxbury_tb)
str(roxbury_tb$REMODEL)
```

We can change the levels as well.

```{r}
roxbury_tb$REMODEL <- factor(roxbury_tb$REMODEL,
                         levels = c("None", "Recent", "Old" ))

str(roxbury_tb$REMODEL)
```

This will be useful in ML tasks. Some algorithms will want the first level as outcome (if coded as 1,2) and some will want the second as the outcome of interest (expect data to be coded as 0,1).

### Some basic tables and pivot tables

`R` has several options of tabulating data or creating pivot tables.

Let's start with a basic table showing how many homes with various number of homes.

```{r}

table(roxbury_tb$ROOMS)

```

Suppose we want to see the frequency of homes with each of these rooms. The function we will use is `prop.table()`, where the above table is input into this function.

```{r}
prop.table(table(roxbury_tb$ROOMS))
```

The above code is very unwieldy. We are basically *piping* the table output into the new function. For this, we can use the `|>` operator (called the pipe operator). This operator will take whatever is preceding the pipe and put it as the *first* argument of the following function.

```{r}

table(roxbury_tb$ROOMS) |> 
  prop.table()
```

```{r}
roxbury_tb$ROOMS |> 
  table() |> 
  prop.table()
```

Let's look at a two-way table. We want to see the number of baths for each remodel category.

```{r}
table(roxbury_tb$REMODEL, roxbury_tb$`FULL BATH`)
```

In this table, note that will the columns are sorted based on the number order, the rows are sorted based on the levels that we defined in the previous code chunk. Now, let's obtain the proportional table for this new two-way table.

```{r}
table(roxbury_tb$REMODEL, roxbury_tb$`FULL BATH`) |> 
  prop.table()
```

By default, frequency distribution is over the entire table. If we want to get this over rows, we can add the `margins = 1` argument.

```{r}
table(roxbury_tb$REMODEL, roxbury_tb$`FULL BATH`) |> 
  prop.table( margin = 1)
```

For column-wise frequency:

```{r}
table(roxbury_tb$REMODEL, roxbury_tb$`FULL BATH`) |> 
  prop.table( margin = 2)
```

We can also obtain Excel-like pivot tables with data presented as other summary stats like mean, median, sum etc by using the `dplyr` library, which is covered in the next section.
