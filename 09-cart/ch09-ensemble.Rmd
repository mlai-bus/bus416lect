---
title: "ch09-ensembles"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(caret)
library(mlbench)
library(tidyverse)
library(skimr)
library(rpart.plot)
library(here)
library(yardstick)
library(pROC)

```



```{r}



bank.df <- read.csv("UniversalBank.csv")
skim(bank.df)
#Let's remove ID and Zip

bank.df <- bank.df %>% 
  select(-c(1,5))

# convert loan application to factor with 1 as the target class

bank.df$Personal.Loan <- factor(as.character(bank.df$Personal.Loan),
                                  levels = c("1", "0"),
                                  labels = c("Yes", "No"))

bank.df <- bank.df %>% 
  rename(Loan = Personal.Loan )
str(bank.df)

#Do a 60-40 split



set.seed(1)
indTrain <- createDataPartition(bank.df$Loan, p = 0.6, times = 1, list = F)

train.df <- bank.df[indTrain,]

test.df <- bank.df[-indTrain,]


```


Thus far, we have looked at single trees. The advantage is that one can derive simple rules to classify new records. A big disadvantage is that single trees can be sensitive to the variables over which the first split happens. Better performance can be obtained when results are combined from multiple trees. One of the first implementations of this is bagging. Bagging refers to __*B*__ ootstrapped __*A*__ggregation


##Bagged Tree

The basic idea of bagged trees is the following:

1. Generate m bootstrapped samples of the data.

2. Train a full tree on each sample.

3. Each tree in the ensemble is used to classify a new record.

4. Majority class is assigned to the record.

Bagged trees are shown to have a better predictive performance than unbagged trees. Let us make a default bagged tree using `ipred` package.




```{r}
cntrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
                      classProbs = T,
                      summaryFunction = twoClassSummary)
set.seed(1089)

tree.caret.bag.cv <- train(Loan ~ . ,
                       data = train.df,
                       method = "treebag",
                       trControl = cntrl,
                       #Use the ROC metric
                       metric = "ROC")


tree.caret.bag.cv

tree.caret.bag.cv$finalModel

# Let us check the performance on the validation set

pred.class.bag <- predict(tree.caret.bag.cv, newdata = test.df)

confusionMatrix(pred.class.bag, test.df$Loan)

# To get AUC, predict the probabilities

pred.class.prob.bag <- predict(tree.caret.bag.cv, 
                               newdata = test.df, type = "prob")

roc.bag <- roc(response = test.df$Loan,
               predictor = pred.class.prob.bag$Yes,
               levels = rev(levels(test.df$Loan)))

auc(roc.bag)



```


We get `AUC = 0.9982`, which is very high. Bagged trees improve the perdictive performance by reducing the variance of the prediction.

The bagged trees however can also suffer from the a similar drawback as the single trees. While, they are more stable, the same set of predictors can exert substantial influence in growing of the trees. This is because the same predictors are considered at each split in designing the tree. While the underlying data may be different for each run of the tree, the trees are not independent of each other and may have structures similar to each other.

This tree correlation can be reduced by adding randomness to the construction of the trees. 

## Random Forests

In random forests, multiple samples are drawn like in bagging but at each split in constructing every tree, a subset of m predictors are randomly chosen. Typically, this number is one-third of the total number of predictors.

In `caret`, this number can become a tuning parameter with the number of variables being five evenly spaced values between 2 to p. Another tuning parameter is the number of trees that can be built for each sample. The default in the `randomForest` package, which is used by `caret` is 500. We can leave it at that.

A random forest built over several tuning parameters and repeated 10 fold cross-validation will take a few hours to run. One quick way to reduce time is to limit the number of cross validation folds and repeats. One could also limit the number of tuning parameter values.

If these fixes are not desirable, the training model should be run taking advantage of parallel processing.

```{r echo = F, eval=FALSE}
cntrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3,
                       classProbs = T,
                      summaryFunction = twoClassSummary)

rfGrid <- expand.grid(mtry = c(2, 4, 6, 8, 10, 12))

set.seed(1089)

tree.caret.rf.cv <- train(Loan ~ . ,
                       data = train.df,
                       method = "rf",
                       trControl = cntrl,
                       tuneGrid = rfGrid,
                       #Use the ROC metric
                       metric = "ROC")

tree.caret.rf.cv

tree.caret.rf.cv$finalModel

# To get AUC, predict the probabilities

pred.class.prob.rf <- predict(tree.caret.bag.cv, 
                               newdata = test.df, type = "prob")

roc.rf <- roc(response = test.df$Loan,
               predictor = pred.class.prob.rf$Yes,
               levels = rev(levels(test.df$Loan)))

auc(roc.rf)


```


Here, we use parallel processing from caret.

```{r}

# install.packages("doParallel")
library(doParallel)

cl <- makePSOCKcluster(4) # Number of processors to be used.
registerDoParallel(cl)

cntrl <- trainControl(method = "repeatedcv", number = 5, repeats = 3,
                       classProbs = T,
                      summaryFunction = twoClassSummary)

rfGrid <- expand.grid(mtry = c(2, 4, 6, 8, 10, 12))


ptm <- proc.time()

set.seed(1089)

tree.caret.rf.mp <- train(Loan ~ . ,
                       data = train.df,
                       method = "rf",
                       trControl = cntrl,
                       tuneGrid = rfGrid,
                       #Use the ROC metric
                       metric = "ROC")

tree.caret.rf.mp

tree.caret.rf.mp$finalModel

# To get AUC, predict the probabilities

pred.class.prob.rfmp <- predict(tree.caret.bag.cv, 
                               newdata = test.df, type = "prob")

roc.rf <- roc(response = test.df$Loan,
               predictor = pred.class.prob.rfmp$Yes,
               levels = rev(levels(test.df$Loan)))

auc(roc.rf)


proc.time() - ptm

stopCluster(cl)
rm(cl)

```


Without the parralization, it would have taken much longer.

Though ensemble methods do not give us clear rules like the inidividual trees, we can obtain a variable importance plot that tells us the relative importance of the various predictors.

```{r}
varImp(tree.caret.rf.mp)

plot(varImp(tree.caret.rf.mp))

```

## Boosted Trees

A third approach to ensembles in contructing classification tree is boosting.

The basic idea behind the AdaBoost, which is the most common implementation of boosting, is to generate a sequence of weak classifiers. At each stage though, the records that are incorrectly classified are given more weight while those correctly classified are given less weigh. Thus, the algorithm learns from miss-classified  records at each stage, focusing on difficult to classify records. The overall

The steps in the algorithm are:

1. Fit an initial tree.

2. Give higher weights to samples that are misclassified.

3. Draw a bootstrapped sample from the weighted records.

4. Fit a new tree to this sample.

5. Repeat steps 2 - 4 M times.


6. Use weighted voting to classify records, with heavier weight for later trees.

```{r}

cntrl <- trainControl(method = "cv", number = 5,
                      classProbs = TRUE,
                      summaryFunction =  twoClassSummary,
                      allowParallel = FALSE)

# The tuning pamareters for boosting are: mfinal (# of trees)
# and maxdepth (the maximum depth of the tree)
# we first build the default tree


ptm <- proc.time()
set.seed(9876)
tree.adaboost <- train(Loan ~ . , data = train.df,
                       method = "AdaBag",
                       trControl = cntrl,
                       metric = "ROC")
               
#tree.adaboost1 <- boosting(Loan ~ ., data = train.df)
#tree.adaboost1

proc.time() - ptm

tree.adaboost


```

The final model chosen by caret had a depth of 3 and 150 trees were built. One could have specified tuning parameter  using the `tuneGrid =` call with more values of the two parameters.

Let us compare the accuracy of the default `caret` tree with the default produced by AdaBag package.

```{r}
#default tree produced by adabag
library(adabag)
tree.ada.def <- boosting(Loan ~ . , data = train.df)


pred.class.prob.ada <- predict(tree.adaboost, 
                               newdata = test.df, type = "prob")

roc.boost <- roc(response = test.df$Loan,
               predictor = pred.class.prob.ada$Yes,
               levels = rev(levels(test.df$Loan)))

auc(roc.boost)


# Now for the default tree

pred.class.prob.ada.def <- predict(tree.ada.def, 
                               newdata = test.df)

# extract the probabilities as a dataframe to get ROC

pred.test <- data.frame(pred.class.prob.ada.def$prob)
roc.boostdef <- roc(response = test.df$Loan,
               predictor = pred.test$X1,
               levels = rev(levels(test.df$Loan)))

auc(roc.boostdef)


```

The performance of this tree is slightly better than the boosted tree created by `caret()`. This is in part due to the fact that the algorithm takes in all the default values of `rpart.control()`, along with the `mfinal = 100`.


Regardless, the boosted trees are a very powerful classification tool. What is interesting is that weaker the initial trees, the stronger is the ensemble. 